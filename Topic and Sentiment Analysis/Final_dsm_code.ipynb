{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a978d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import gensim\n",
    "import numpy as np\n",
    "from gensim import corpora\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('vader_lexicon', quiet=True)\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "input_path = \"C:/Users/User/OneDrive/Desktop/dsm_project/cleaneddataset/st_louis_reviews.csv\"\n",
    "output_dir = \"C:/Users/User/OneDrive/Desktop/dsm_project/cleaneddataset/output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "min_docs_needed = 10\n",
    "\n",
    "df = pd.read_csv(input_path)\n",
    "assert 'text' in df.columns, \"CSV must contain 'text' column\"\n",
    "df['text'] = df['text'].fillna('').astype(str)\n",
    "\n",
    "def preprocess(text):\n",
    "    try:\n",
    "        tokens = nltk.word_tokenize(text.lower())\n",
    "        tokens = [word for word in tokens if word.isalpha()]\n",
    "        tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "        return tokens if tokens else ['placeholder']\n",
    "    except:\n",
    "        return ['placeholder']\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "print(\"Performing sentiment analysis with adjusted thresholds...\")\n",
    "\n",
    "df['compound'] = df['text'].progress_apply(lambda x: sia.polarity_scores(x)['compound'])\n",
    "\n",
    "def classify_sentiment(score):\n",
    "    if score >= 0.3:\n",
    "        return 'positive'\n",
    "    elif score <= -0.3:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "df['sentiment'] = df['compound'].apply(classify_sentiment)\n",
    "\n",
    "df[['text', 'compound', 'sentiment']].to_csv(os.path.join(output_dir, \"review_sentiment_map.csv\"), index=False)\n",
    "\n",
    "positive_reviews = df[df['sentiment'] == 'positive']['text']\n",
    "negative_reviews = df[df['sentiment'] == 'negative']['text']\n",
    "\n",
    "def get_topics(reviews, label, num_topics=5, num_words=6):\n",
    "    if len(reviews) < min_docs_needed:\n",
    "        print(f\"Not enough {label} reviews ({len(reviews)}).\")\n",
    "        return [], None, [], None, []\n",
    "\n",
    "    texts = reviews.progress_apply(preprocess).tolist()\n",
    "    texts = [t for t in texts if len(t) > 0]\n",
    "    dictionary = corpora.Dictionary(texts)\n",
    "    dictionary.filter_extremes(no_below=2, no_above=0.9)\n",
    "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "    if len(dictionary) < num_topics:\n",
    "        num_topics = max(2, len(dictionary) // 5)\n",
    "\n",
    "    lda = gensim.models.LdaModel(corpus, num_topics=num_topics, id2word=dictionary, passes=10, random_state=42)\n",
    "    topics = lda.print_topics(num_words=num_words)\n",
    "\n",
    "    topic_keywords = []\n",
    "    for i, topic in enumerate(topics):\n",
    "        try:\n",
    "            words = [w.split(\"*\")[1].replace('\"', '').strip() for w in topic[1].split(\"+\")]\n",
    "            topic_keywords.append({\n",
    "                'Sentiment': label,\n",
    "                'Topic': f\"Topic {i+1}\",\n",
    "                'Keywords': \", \".join(words)\n",
    "            })\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    return topic_keywords, lda, corpus, dictionary, texts\n",
    "\n",
    "topics_data = []\n",
    "\n",
    "pos_topics, lda_pos, corpus_pos, dict_pos, texts_pos = get_topics(positive_reviews, 'positive')\n",
    "topics_data.extend(pos_topics)\n",
    "\n",
    "neg_topics, lda_neg, corpus_neg, dict_neg, texts_neg = get_topics(negative_reviews, 'negative')\n",
    "topics_data.extend(neg_topics)\n",
    "\n",
    "if topics_data:\n",
    "    pd.DataFrame(topics_data).to_csv(os.path.join(output_dir, \"st_louis_reviews_topics.csv\"), index=False)\n",
    "\n",
    "def assign_topics(corpus, lda_model):\n",
    "    return [max(lda_model.get_document_topics(doc), key=lambda x: x[1])[0] for doc in corpus]\n",
    "\n",
    "df_pos = pd.DataFrame({'text': positive_reviews.values})\n",
    "df_neg = pd.DataFrame({'text': negative_reviews.values})\n",
    "\n",
    "if lda_pos and corpus_pos:\n",
    "    df_pos['dominant_topic'] = assign_topics(corpus_pos, lda_pos)\n",
    "\n",
    "if lda_neg and corpus_neg:\n",
    "    df_neg['dominant_topic'] = assign_topics(corpus_neg, lda_neg)\n",
    "\n",
    "sentiment_counts = df['sentiment'].value_counts()\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.pie(sentiment_counts, labels=sentiment_counts.index, autopct='%1.1f%%', colors=['lightgreen', 'salmon', 'gray'])\n",
    "plt.title(\"Sentiment Distribution\")\n",
    "plt.savefig(os.path.join(output_dir, \"sentiment_pie_chart.png\"))\n",
    "plt.close()\n",
    "\n",
    "def plot_keyword_bar(topics, label):\n",
    "    if not topics:\n",
    "        return\n",
    "    names = [t['Topic'] for t in topics]\n",
    "    counts = [len(t['Keywords'].split(\", \")) for t in topics]\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(names, counts)\n",
    "    plt.title(f\"Keyword Count per {label.capitalize()} Topic\")\n",
    "    plt.ylabel(\"Keyword Count\")\n",
    "    plt.savefig(os.path.join(output_dir, f\"{label}_topics_bar_chart.png\"))\n",
    "    plt.close()\n",
    "\n",
    "plot_keyword_bar(pos_topics, 'positive')\n",
    "plot_keyword_bar(neg_topics, 'negative')\n",
    "\n",
    "def plot_topic_distribution(df_subset, label):\n",
    "    if 'dominant_topic' not in df_subset.columns:\n",
    "        return\n",
    "    topic_counts = df_subset['dominant_topic'].value_counts().sort_index()\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar([f\"Topic {i+1}\" for i in topic_counts.index], topic_counts.values)\n",
    "    plt.title(f\"Review Count per Topic - {label.capitalize()}\")\n",
    "    plt.xlabel(\"Topic\")\n",
    "    plt.ylabel(\"Number of Reviews\")\n",
    "    plt.savefig(os.path.join(output_dir, f\"{label}_topic_distribution.png\"))\n",
    "    plt.close()\n",
    "\n",
    "plot_topic_distribution(df_pos, 'positive')\n",
    "plot_topic_distribution(df_neg, 'negative')\n",
    "\n",
    "print(\"Analysis completed successfully with better sentiment thresholds.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9de6ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "nltk.download('stopwords', quiet=True)\n",
    "tqdm.pandas()\n",
    "\n",
    "input_path = \"C:/Users/User/OneDrive/Desktop/dsm_project/cleaneddataset/st_louis_reviews.csv\"\n",
    "output_dir = \"C:/Users/User/OneDrive/Desktop/dsm_project/cleaneddataset/output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_csv = os.path.join(output_dir, \"ml_rating_predictions.csv\")\n",
    "\n",
    "df = pd.read_csv(input_path)\n",
    "assert 'text' in df.columns and 'stars' in df.columns, \"CSV must contain 'text' and 'stars'\"\n",
    "df['text'] = df['text'].fillna('').astype(str)\n",
    "df = df[df['stars'].notnull()]\n",
    "df['stars'] = df['stars'].astype(int)\n",
    "\n",
    "X = df['text']\n",
    "y = df['stars']\n",
    "\n",
    "# --- TF-IDF Vectorization ---\n",
    "print(\"Vectorizing reviews with TF-IDF...\")\n",
    "vectorizer = TfidfVectorizer(\n",
    "    stop_words=stopwords.words('english'),\n",
    "    max_features=5000,\n",
    "    ngram_range=(1, 2)\n",
    ")\n",
    "X_vec = vectorizer.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_vec, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Training logistic regression...\")\n",
    "clf = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Predicting on test data...\")\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "exact_accuracy = accuracy_score(y_test, y_pred)\n",
    "relaxed_correct = (abs(y_test.values - y_pred) <= 1)\n",
    "relaxed_accuracy = relaxed_correct.mean()\n",
    "\n",
    "print(f\"\\n Exact Match Accuracy: {exact_accuracy * 100:.2f}%\")\n",
    "print(f\"Relaxed Accuracy (Â±1 star): {relaxed_accuracy * 100:.2f}%\")\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'text': df.iloc[y_test.index]['text'].values,\n",
    "    'actual_rating': y_test.values,\n",
    "    'predicted_rating': y_pred,\n",
    "    'correct_prediction': relaxed_correct\n",
    "})\n",
    "results_df.to_csv(output_csv, index=False)\n",
    "print(f\"Predictions saved to: {output_csv}\")\n",
    "\n",
    "cm_exact = confusion_matrix(y_test, y_pred, labels=[1, 2, 3, 4, 5])\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_exact, annot=True, fmt='d', cmap='Blues', xticklabels=[1, 2, 3, 4, 5], yticklabels=[1, 2, 3, 4, 5])\n",
    "plt.xlabel(\"Predicted Rating\")\n",
    "plt.ylabel(\"Actual Rating\")\n",
    "plt.title(\"Confusion Matrix (Exact Match)\")\n",
    "plt.tight_layout()\n",
    "exact_cm_path = os.path.join(output_dir, \"confusion_matrix_exact.png\")\n",
    "plt.savefig(exact_cm_path)\n",
    "plt.close()\n",
    "print(f\"Exact confusion matrix saved to: {exact_cm_path}\")\n",
    "\n",
    "def relaxed_cm(true, pred, labels=[1, 2, 3, 4, 5]):\n",
    "    relaxed_pred = []\n",
    "    for t, p in zip(true, pred):\n",
    "        if abs(t - p) <= 1:\n",
    "            relaxed_pred.append(p)\n",
    "        else:\n",
    "            relaxed_pred.append(-1) \n",
    "    all_labels = labels + [-1]\n",
    "    cm = confusion_matrix(true, relaxed_pred, labels=all_labels)\n",
    "    return cm, all_labels\n",
    "\n",
    "cm_relaxed, all_labels = relaxed_cm(y_test.values, y_pred)\n",
    "plt.figure(figsize=(9, 6))\n",
    "sns.heatmap(\n",
    "    cm_relaxed,\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cmap='YlOrRd',\n",
    "    xticklabels=[str(l) if l != -1 else \"Off\" for l in all_labels],\n",
    "    yticklabels=[str(l) for l in all_labels if l != -1]\n",
    ")\n",
    "plt.xlabel(\"Predicted Rating (Â±1 accepted)\")\n",
    "plt.ylabel(\"Actual Rating\")\n",
    "plt.title(\"Confusion Matrix (Relaxed Â±1)\")\n",
    "plt.tight_layout()\n",
    "relaxed_cm_path = os.path.join(output_dir, \"confusion_matrix_relaxed.png\")\n",
    "plt.savefig(relaxed_cm_path)\n",
    "plt.close()\n",
    "print(f\"Relaxed confusion matrix saved to: {relaxed_cm_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a95901",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import gensim\n",
    "import numpy as np\n",
    "from gensim import corpora\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('vader_lexicon', quiet=True)\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "input_path = \"C:/Users/User/OneDrive/Desktop/dsm_project/cleaneddataset/philly_reviews.csv\"\n",
    "output_dir = \"C:/Users/User/OneDrive/Desktop/dsm_project/cleaneddataset/philly_output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "min_docs_needed = 10\n",
    "\n",
    "df = pd.read_csv(input_path)\n",
    "assert 'text' in df.columns, \"CSV must contain 'text' column\"\n",
    "df['text'] = df['text'].fillna('').astype(str)\n",
    "\n",
    "def preprocess(text):\n",
    "    try:\n",
    "        tokens = nltk.word_tokenize(text.lower())\n",
    "        tokens = [word for word in tokens if word.isalpha()]\n",
    "        tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "        return tokens if tokens else ['placeholder']\n",
    "    except:\n",
    "        return ['placeholder']\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "print(\"Performing sentiment analysis with adjusted thresholds...\")\n",
    "\n",
    "df['compound'] = df['text'].progress_apply(lambda x: sia.polarity_scores(x)['compound'])\n",
    "\n",
    "def classify_sentiment(score):\n",
    "    if score >= 0.3:\n",
    "        return 'positive'\n",
    "    elif score <= -0.3:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "df['sentiment'] = df['compound'].apply(classify_sentiment)\n",
    "\n",
    "df[['text', 'compound', 'sentiment']].to_csv(os.path.join(output_dir, \"review_sentiment_map.csv\"), index=False)\n",
    "\n",
    "positive_reviews = df[df['sentiment'] == 'positive']['text']\n",
    "negative_reviews = df[df['sentiment'] == 'negative']['text']\n",
    "\n",
    "def get_topics(reviews, label, num_topics=5, num_words=6):\n",
    "    if len(reviews) < min_docs_needed:\n",
    "        print(f\"Not enough {label} reviews ({len(reviews)}).\")\n",
    "        return [], None, [], None, []\n",
    "\n",
    "    texts = reviews.progress_apply(preprocess).tolist()\n",
    "    texts = [t for t in texts if len(t) > 0]\n",
    "    dictionary = corpora.Dictionary(texts)\n",
    "    dictionary.filter_extremes(no_below=2, no_above=0.9)\n",
    "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "    if len(dictionary) < num_topics:\n",
    "        num_topics = max(2, len(dictionary) // 5)\n",
    "\n",
    "    lda = gensim.models.LdaModel(corpus, num_topics=num_topics, id2word=dictionary, passes=10, random_state=42)\n",
    "    topics = lda.print_topics(num_words=num_words)\n",
    "\n",
    "    topic_keywords = []\n",
    "    for i, topic in enumerate(topics):\n",
    "        try:\n",
    "            words = [w.split(\"*\")[1].replace('\"', '').strip() for w in topic[1].split(\"+\")]\n",
    "            topic_keywords.append({\n",
    "                'Sentiment': label,\n",
    "                'Topic': f\"Topic {i+1}\",\n",
    "                'Keywords': \", \".join(words)\n",
    "            })\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    return topic_keywords, lda, corpus, dictionary, texts\n",
    "\n",
    "topics_data = []\n",
    "\n",
    "pos_topics, lda_pos, corpus_pos, dict_pos, texts_pos = get_topics(positive_reviews, 'positive')\n",
    "topics_data.extend(pos_topics)\n",
    "\n",
    "neg_topics, lda_neg, corpus_neg, dict_neg, texts_neg = get_topics(negative_reviews, 'negative')\n",
    "topics_data.extend(neg_topics)\n",
    "\n",
    "if topics_data:\n",
    "    pd.DataFrame(topics_data).to_csv(os.path.join(output_dir, \"st_louis_reviews_topics.csv\"), index=False)\n",
    "\n",
    "def assign_topics(corpus, lda_model):\n",
    "    return [max(lda_model.get_document_topics(doc), key=lambda x: x[1])[0] for doc in corpus]\n",
    "\n",
    "df_pos = pd.DataFrame({'text': positive_reviews.values})\n",
    "df_neg = pd.DataFrame({'text': negative_reviews.values})\n",
    "\n",
    "if lda_pos and corpus_pos:\n",
    "    df_pos['dominant_topic'] = assign_topics(corpus_pos, lda_pos)\n",
    "\n",
    "if lda_neg and corpus_neg:\n",
    "    df_neg['dominant_topic'] = assign_topics(corpus_neg, lda_neg)\n",
    "\n",
    "sentiment_counts = df['sentiment'].value_counts()\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.pie(sentiment_counts, labels=sentiment_counts.index, autopct='%1.1f%%', colors=['lightgreen', 'salmon', 'gray'])\n",
    "plt.title(\"Sentiment Distribution\")\n",
    "plt.savefig(os.path.join(output_dir, \"sentiment_pie_chart.png\"))\n",
    "plt.close()\n",
    "\n",
    "def plot_keyword_bar(topics, label):\n",
    "    if not topics:\n",
    "        return\n",
    "    names = [t['Topic'] for t in topics]\n",
    "    counts = [len(t['Keywords'].split(\", \")) for t in topics]\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(names, counts)\n",
    "    plt.title(f\"Keyword Count per {label.capitalize()} Topic\")\n",
    "    plt.ylabel(\"Keyword Count\")\n",
    "    plt.savefig(os.path.join(output_dir, f\"{label}_topics_bar_chart.png\"))\n",
    "    plt.close()\n",
    "\n",
    "plot_keyword_bar(pos_topics, 'positive')\n",
    "plot_keyword_bar(neg_topics, 'negative')\n",
    "\n",
    "def plot_topic_distribution(df_subset, label):\n",
    "    if 'dominant_topic' not in df_subset.columns:\n",
    "        return\n",
    "    topic_counts = df_subset['dominant_topic'].value_counts().sort_index()\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar([f\"Topic {i+1}\" for i in topic_counts.index], topic_counts.values)\n",
    "    plt.title(f\"Review Count per Topic - {label.capitalize()}\")\n",
    "    plt.xlabel(\"Topic\")\n",
    "    plt.ylabel(\"Number of Reviews\")\n",
    "    plt.savefig(os.path.join(output_dir, f\"{label}_topic_distribution.png\"))\n",
    "    plt.close()\n",
    "\n",
    "plot_topic_distribution(df_pos, 'positive')\n",
    "plot_topic_distribution(df_neg, 'negative')\n",
    "\n",
    "print(\"Analysis completed successfully with better sentiment thresholds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418ed3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "nltk.download('stopwords', quiet=True)\n",
    "tqdm.pandas()\n",
    "\n",
    "input_path = \"C:/Users/User/OneDrive/Desktop/dsm_project/cleaneddataset/philly_reviews.csv\"\n",
    "output_dir = \"C:/Users/User/OneDrive/Desktop/dsm_project/cleaneddataset/philly_output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_csv = os.path.join(output_dir, \"ml_rating_predictions.csv\")\n",
    "\n",
    "df = pd.read_csv(input_path)\n",
    "assert 'text' in df.columns and 'stars' in df.columns, \"CSV must contain 'text' and 'stars'\"\n",
    "df['text'] = df['text'].fillna('').astype(str)\n",
    "df = df[df['stars'].notnull()]\n",
    "df['stars'] = df['stars'].astype(int)\n",
    "\n",
    "X = df['text']\n",
    "y = df['stars']\n",
    "\n",
    "print(\"Vectorizing reviews with TF-IDF...\")\n",
    "vectorizer = TfidfVectorizer(\n",
    "    stop_words=stopwords.words('english'),\n",
    "    max_features=5000,\n",
    "    ngram_range=(1, 2)\n",
    ")\n",
    "X_vec = vectorizer.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_vec, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Training logistic regression...\")\n",
    "clf = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Predicting on test data...\")\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "exact_accuracy = accuracy_score(y_test, y_pred)\n",
    "relaxed_correct = (abs(y_test.values - y_pred) <= 1)\n",
    "relaxed_accuracy = relaxed_correct.mean()\n",
    "\n",
    "print(f\"\\n Exact Match Accuracy: {exact_accuracy * 100:.2f}%\")\n",
    "print(f\" Relaxed Accuracy (Â±1 star): {relaxed_accuracy * 100:.2f}%\")\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'text': df.iloc[y_test.index]['text'].values,\n",
    "    'actual_rating': y_test.values,\n",
    "    'predicted_rating': y_pred,\n",
    "    'correct_prediction': relaxed_correct\n",
    "})\n",
    "results_df.to_csv(output_csv, index=False)\n",
    "print(f\"Predictions saved to: {output_csv}\")\n",
    "\n",
    "cm_exact = confusion_matrix(y_test, y_pred, labels=[1, 2, 3, 4, 5])\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_exact, annot=True, fmt='d', cmap='Blues', xticklabels=[1, 2, 3, 4, 5], yticklabels=[1, 2, 3, 4, 5])\n",
    "plt.xlabel(\"Predicted Rating\")\n",
    "plt.ylabel(\"Actual Rating\")\n",
    "plt.title(\"Confusion Matrix (Exact Match)\")\n",
    "plt.tight_layout()\n",
    "exact_cm_path = os.path.join(output_dir, \"confusion_matrix_exact.png\")\n",
    "plt.savefig(exact_cm_path)\n",
    "plt.close()\n",
    "print(f\"ðŸ“Š Exact confusion matrix saved to: {exact_cm_path}\")\n",
    "\n",
    "def relaxed_cm(true, pred, labels=[1, 2, 3, 4, 5]):\n",
    "    relaxed_pred = []\n",
    "    for t, p in zip(true, pred):\n",
    "        if abs(t - p) <= 1:\n",
    "            relaxed_pred.append(p)\n",
    "        else:\n",
    "            relaxed_pred.append(-1) \n",
    "    all_labels = labels + [-1]\n",
    "    cm = confusion_matrix(true, relaxed_pred, labels=all_labels)\n",
    "    return cm, all_labels\n",
    "\n",
    "cm_relaxed, all_labels = relaxed_cm(y_test.values, y_pred)\n",
    "plt.figure(figsize=(9, 6))\n",
    "sns.heatmap(\n",
    "    cm_relaxed,\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cmap='YlOrRd',\n",
    "    xticklabels=[str(l) if l != -1 else \"Off\" for l in all_labels],\n",
    "    yticklabels=[str(l) for l in all_labels if l != -1]\n",
    ")\n",
    "plt.xlabel(\"Predicted Rating (Â±1 accepted)\")\n",
    "plt.ylabel(\"Actual Rating\")\n",
    "plt.title(\"Confusion Matrix (Relaxed Â±1)\")\n",
    "plt.tight_layout()\n",
    "relaxed_cm_path = os.path.join(output_dir, \"confusion_matrix_relaxed.png\")\n",
    "plt.savefig(relaxed_cm_path)\n",
    "plt.close()\n",
    "print(f\"Relaxed confusion matrix saved to: {relaxed_cm_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
